{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Setting everything up\n",
    "\n",
    "Open this repository in a GitHub Codespace.\n",
    "Before you start with anything else, make sure you setup the infrastructure required. Follow the readme file in the root folder to do this!\n",
    "\n",
    "To start with Phase 1, if not already done run this in the top level folder:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://cog-sli73xznuikkc.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if stuff works in general, you can run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spending time with my loved ones. Whether it's my family, friends, or significant other, being able to be with the people I care about brings me immense joy and fulfillment. There's something truly special about the laughter, conversation, and connection that comes from spending quality time together. Building memories and sharing experiences with the people who mean the most to me is what I cherish the most in life.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = model_name,    \n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_or_false = \"true_or_false\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    # \"\"\"\n",
    "    # # Ask a question\n",
    "    # \"\"\"\n",
    "\n",
    "    # Send a completion call to generate an answer\n",
    "    print('Sending a request to openai')\n",
    "    \n",
    "    start_phrase =  ask.question\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : start_phrase}, \n",
    "                     { \"role\" : \"system\", \"content\" : \"Answer this question as short as possible. Answer questions without the choice number:\"}]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    print(response)\n",
    "    answer = Answer(answer=response.choices[0].message.content)\n",
    "    answer.correlationToken = ask.correlationToken\n",
    "    answer.promptTokensUsed = response.usage.prompt_tokens\n",
    "    answer.completionTokensUsed = response.usage.completion_tokens\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a request to openai\n",
      "Robert Downey Jr.\n",
      "ChatCompletion(id='chatcmpl-9cUhJPZZLqIUZxycNM300Sitw4Jpk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Robert Downey Jr.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1718961493, model='gpt-35-turbo', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=53, total_tokens=58), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='Robert Downey Jr.' correlationToken=None promptTokensUsed=53 completionTokensUsed=5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ask = Ask(question=\"Who is the actor behind iron man?  A. Bill Gates, B. Robert Downey Jr, C. Jeff Bezos.\", type=QuestionType.multiple_choice)\n",
    "answer = await ask_question(ask)\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Questions\n",
    "Sample Questions could look like this. Make sure your answer exactly  matches the required answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "{\n",
    "    \"id\": 3,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Which movie features a plot where a young girl named Dorothy is transported to a magical land via a tornado? 1) Cinderella 2) The Wizard of Oz 3) Alice in Wonderland 4) The Little Mermaid\",\n",
    "    \"answer\": \"The Wizard of Oz\",\n",
    "    \"type\": \"multiple_choice\"\n",
    "},\n",
    "{\n",
    "    \"id\": 4,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Is Yoda a character from the Star Trek universe: True or False?\",\n",
    "    \"answer\": false,\n",
    "    \"type\": \"true_or_false\"\n",
    "},\n",
    "{\n",
    "    \"id\": 5,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"How many movies are there in 'The Lord of the Rings' trilogy directed by Peter Jackson?\",\n",
    "    \"answer\": 3,\n",
    "    \"type\": \"estimation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). \n",
    "You can test your app locally using uvicorn. (See Readme.md for details.)\n",
    "\n",
    "Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase1 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
